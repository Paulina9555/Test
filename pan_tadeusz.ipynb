{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paulina9555/Test/blob/master/pan_tadeusz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ae3caf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:27.743153Z",
          "start_time": "2023-02-23T19:29:27.723568Z"
        },
        "id": "28ae3caf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPool1D, Dropout, BatchNormalization, Bidirectional, Flatten\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import tensorflow.keras.preprocessing.text as kpt\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff578d0e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:41.163529Z",
          "start_time": "2023-02-23T19:29:41.150092Z"
        },
        "id": "ff578d0e"
      },
      "outputs": [],
      "source": [
        "with open(\"pan_taduesz.txt\",\"r\", encoding = \"UTF-8\") as file:\n",
        "    df = file.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0b4ab9a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:41.384141Z",
          "start_time": "2023-02-23T19:29:41.366837Z"
        },
        "id": "f0b4ab9a"
      },
      "outputs": [],
      "source": [
        "doc = [doc.replace(\"\\n\",\"\").strip() for doc in df if len(doc) >= 30 and len(doc) <= 60 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b33c31f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:42.143080Z",
          "start_time": "2023-02-23T19:29:42.127413Z"
        },
        "id": "5b33c31f"
      },
      "outputs": [],
      "source": [
        "text = \"\".join(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4b896e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:42.980751Z",
          "start_time": "2023-02-23T19:29:42.840062Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b4b896e",
        "outputId": "f1bfffc6-66e7-436a-d348-d7de2c065f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba sekwencji: 141355\n"
          ]
        }
      ],
      "source": [
        "# Wyodrębniamy sekwencje składajace się z 60 znaków.\n",
        "maxlen = 60\n",
        "\n",
        "# Nowa sekwencja jest próbkowana co 3 znaki.\n",
        "step = 3\n",
        "\n",
        "# Zmienna, w której zapisywane będą wyodrębnione sekwencje.\n",
        "sentences = []\n",
        "\n",
        "# Zmienna, w której zapisywane będą kolejne znaki (cele).\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Liczba sekwencji:', len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e76bcae9-ed67-4824-98da-da26fae3dd6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e76bcae9-ed67-4824-98da-da26fae3dd6b",
        "outputId": "98cc5b0b-8151-4d64-b09d-71dc82e66bbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141355"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "848f2979",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:43.042478Z",
          "start_time": "2023-02-23T19:29:43.010562Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "848f2979",
        "outputId": "4fcb2698-ace3-42d4-c708-05a3b7183a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba unikatowych znaków: 83\n"
          ]
        }
      ],
      "source": [
        "# Lista unikatowych znaków wchodzących w skład korpusu.\n",
        "chars = sorted(list(set(text)))\n",
        "print('Liczba unikatowych znaków:', len(chars))\n",
        "# Słownik przypisujące unikatowe znaki do ich indeksów.\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644c7364",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:50.989773Z",
          "start_time": "2023-02-23T19:29:43.132460Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "644c7364",
        "outputId": "81e42dee-8cd5-45f2-eec2-958ddce19c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tworzenie wektorów...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-9741607de9ed>:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
            "<ipython-input-18-9741607de9ed>:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
          ]
        }
      ],
      "source": [
        "# Znaki są zapisywane w formie tablic binarnych przy użyciu kodowania z gorącą jedynką.\n",
        "print('Tworzenie wektorów...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2afe8114-f93f-4b41-b77c-d212cec73212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2afe8114-f93f-4b41-b77c-d212cec73212",
        "outputId": "561db0eb-e6a2-4e30-b18e-c2077fc0baf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False,  True, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "x[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eyxBVNkcQGp",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:55.082955Z",
          "start_time": "2023-02-23T19:29:50.991988Z"
        },
        "id": "7eyxBVNkcQGp"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    LSTM(32, input_shape=(maxlen, len(chars)), return_sequences = True),\n",
        "    LSTM(64, input_shape=(maxlen, len(chars)), return_sequences = True),\n",
        "    LSTM(128),\n",
        "    Dense(len(chars), activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e260434",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:55.144924Z",
          "start_time": "2023-02-23T19:29:55.087538Z"
        },
        "id": "3e260434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89478b31-87fa-4162-b5e6-7c2fa36cdb15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ],
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, run_eagerly=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531ae6b5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-23T19:29:55.175498Z",
          "start_time": "2023-02-23T19:29:55.150763Z"
        },
        "id": "531ae6b5"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0daf10e0",
      "metadata": {
        "id": "0daf10e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83894859-0c14-4f04-abb5-4aebcf56f28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f3db810d2d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f3db810d2d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "277/277 [==============================] - 22s 73ms/step - loss: 3.4073\n",
            "epoch 2\n",
            "277/277 [==============================] - 19s 70ms/step - loss: 3.3747\n",
            "epoch 3\n",
            "277/277 [==============================] - 18s 65ms/step - loss: 3.3521\n",
            "epoch 4\n",
            "277/277 [==============================] - 19s 70ms/step - loss: 3.2138\n",
            "epoch 5\n",
            "277/277 [==============================] - 19s 67ms/step - loss: 3.0779\n",
            "epoch 6\n",
            "277/277 [==============================] - 18s 65ms/step - loss: 2.9608\n",
            "epoch 7\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 2.8252\n",
            "epoch 8\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 2.6998\n",
            "epoch 9\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 2.6103\n",
            "epoch 10\n",
            "277/277 [==============================] - 18s 64ms/step - loss: 2.5462\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czecze szęczy z podowienie,Zrzecze w taszcze szęczy szczy się się się z tacha.Podzy się z waczy się się z pomy się z padawie,Waczy szęcze się tasz szęcza w podzy się na paranie,Taszcze na szczech waszecza się szłach się gojech,Podza się szę w się z szęcza z poszcza z tarach,Porzech szach się szęczy się z wadzach tach sięchy,Wada przecza szczy się z waka z podzach się podzy,Tadzie szę z paczecz zacz\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.5\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba cie przeczy waszecze prosznawiedał z szęcych krzycie o siesz zyszco zaczy.Dorzycy sich war zczył zanał — z wystczy z poruwy,Styczesz wze tmocie w pachyże sznanichnie z tadawiy.«Wabawy my chyśch poszyczał z padnie z załszesznach:Wrachch zadana szęda nie szmęa sza koboczy.Pdzycze pakrach chrachnie z z trachczy j w cienica,A z się sz się sał zaczky się wado pepamaczy;Odob male pawamą sacza, pojech się\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.0\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba cąm kula: rzy przębieconaćZig okawimk kobół Ariegnejsdy kartegło nisuBiBeszwiejczy tał śęłiemide ztydzie, Poszećł na śrtywia;Dhwe kzojyjna! zleck rzeszwicty ałnu suszać.Pydmyju ś drysky, Wojczeł olskczo wczyrankwki.rzałdy laz, czynyłaj. grznia o swgzawdićUzernał waunosz łiacmyło» zcharo,Mrzerkożjet ogoa?Podną dok zstiś się, ponąDuciec ogkenzczcie zwachchłiesny — z nal ciaża peczlych cyc tama natęm;\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czodoj, de pawąć zzeżuwan.Tałzwę, róu szpąś, dtaj midak owechi;Kdyką z. snach trGskyły ma  zpzłyknu, wumolesz kłtodni;Tą wcochcząc mia zacsęczonoł kowate barogo,I ryęn Am się acherni « umiejraWe,Tódstę, Jech: tagernncy szwajrie ż dnoszbieł.Ttdrac zkańłnia; tzokkichwa;Taży gub —lbanlósa,cyKochy wczylieć; ochuć zn…eczą?Uach, z śdzynicech w opwem mają snukzdót ddętushn!m!j  katy znań chumą, jał bysły \n",
            "epoch 11\n",
            "277/277 [==============================] - 18s 65ms/step - loss: 2.4993\n",
            "epoch 12\n",
            "277/277 [==============================] - 19s 70ms/step - loss: 2.4599\n",
            "epoch 13\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 2.4255\n",
            "epoch 14\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 2.3953\n",
            "epoch 15\n",
            "277/277 [==============================] - 18s 66ms/step - loss: 2.3656\n",
            "epoch 16\n",
            "277/277 [==============================] - 20s 72ms/step - loss: 2.3399\n",
            "epoch 17\n",
            "277/277 [==============================] - 20s 72ms/step - loss: 2.3146\n",
            "epoch 18\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 2.2918\n",
            "epoch 19\n",
            "277/277 [==============================] - 19s 68ms/step - loss: 2.2713\n",
            "epoch 20\n",
            "277/277 [==============================] - 19s 70ms/step - loss: 2.2513\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czy szeka się zaszy się zamie,By wysze się podzie zasze wysze koszy poszy,Z pod się wielki wieszczy wyszy pod podera,Ko wieczy się zadzie wysze się za podzie,A podzie wydzie zasze zapał pod się zadzie,Je jak podanie wieczy się zasze wie podzie,Do nie był się wyszał podzie się zamienie,W podział poszał się zadzie wyszy się zamie,Od podko się zadzie zaszy na podzie zadzie,Jem zaszczy się zam podzie z\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.5\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czy wieczy, gtara jak tu cie wadzie,«Je wiał nie zachunie mowa i popiedziem,A stak zadzie ochała oszy potrzyszym.Om adwą zaszczy, na wieczy kon się zabonie,Z pan kłacie posią przyczał oczył na poszę,Nie się wydziem papnu podaw zaszczy, pokoru,Telko dzie posze tako i byt się wali,I ban nie zaszczych się zadzia koszy z woszy,Polczył się zadzie mzadzia i wyskam zaszczy,Z się wenkim dwie wieli na spody\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.0\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czwą grzedzał,j no oczy i jachneBażem mów., całe tyśsie calko, kodzie na gdychyć,«Bók osubło, żeście, — papnim snoszcząm zieskuW,Pam dzi drząm pożdy, ze tać gdzie z« powityZ posa tubby — alczą się skrushny, dwo opudzie,Rie nie gopamkic rzeźszych ogrundę groją!Mankym popiedjacze Pody awto dzie wo im,Gdo ziekzą poskarzaś, i żez Jegochłą,Chrywna kiesowość, skad, utez ktaz lać gronięI stzym nie Dobna o\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czy got, tyt cak rlzotyciIm wlą Jaz weśly, pózcze, sięz prze, tzej że rężduchnii;Jy. citłą, aran ratly, ty eprutysujeJeby reżkąj jak: mud, byż Rzysny law sie dwiŻaZ szen pie z lacskić» ewczył, chyld… bnie simy,Wne zac bnarde z cymią smlawy gobutać,Takomy śm goscygt!, (lechchnem Wace dłuszyTsto zadko błoby wiedno zroda twu wiacówPatkumił Jo męgojęwo. cze dze w wijem,O tad żewskoń mrodtzym, Codz obry\n",
            "epoch 21\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 2.2319\n",
            "epoch 22\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 2.2142\n",
            "epoch 23\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 2.1987\n",
            "epoch 24\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 2.1811\n",
            "epoch 25\n",
            "277/277 [==============================] - 19s 70ms/step - loss: 2.1657\n",
            "epoch 26\n",
            "277/277 [==============================] - 19s 70ms/step - loss: 2.1509\n",
            "epoch 27\n",
            "277/277 [==============================] - 20s 72ms/step - loss: 2.1355\n",
            "epoch 28\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 2.1219\n",
            "epoch 29\n",
            "277/277 [==============================] - 19s 68ms/step - loss: 2.1085\n",
            "epoch 30\n",
            "277/277 [==============================] - 21s 76ms/step - loss: 2.0953\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czarze z porzedził się przejerze,Za starzał się z głowie na tylko po strzerzenie,Od wierzał się z porzedział się z poraszki z przedzienie,Wielkie się na strzerzej się podłodziej się z przedzienie,Za strzerzej się z przestał się z przed szlachty na przydział,Chrzest z porzedział się szerwał pod wierzej zarzenie,Takierz się z przerwała strzedł na tylko się z przedzienie,Za strzerzej się za strzerzej \n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.5\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czasie czarną się z mosił w przed wtarzy,Lecz strzesłem świedzić czystne ustrze jeż się z porzedzie,Dziucie kończą wej nastwie zartarza nie przedzieńce,Przy ostał drzerwy się zarzedził się obie,I Rybę się z parat obia z wierznie się przebie,Przyjeranie koład trzedł roznam w te miedziecie,Jest tej murzą zarobił za zarząc się korodzie,Oni się starzą dzierze w jakier w posiastwie,Gdzieszkie się się z \n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.0\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czylijał, i tderlawie czani.I ryk, knierą lat z mociary o córny zmiśra sęwilę.Wgrolich, też, wieszczek cielikikstami z gcy żypiebia!Telijenem, że alest przyszcznikijągo ilajy.Krrowożył; je niewłasencu. czorze zzorzataZa pierzyny proniara i ześlianik z spogatam,Ktrzy do myłłu porzudnąj, robiczę się głorem,Aż goty mił i mlacześ, czar, strzeliszen trowie;Błoty odmerzów brus dłognier do oscy sweska.Doz\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba człu zięje grzypiącknęścich ożną!Brzelewząszkikne zakrórrozy odmijegrów…»Zochońą — (mić, co trzukie sebem w Lici( na z roznuja;)Obryjby, zykamki, ko jemkuch traśniek zmuli,»«Wieszłuk, nigroc klaceją, to tylcą bym szchomieni.Chlejko, Syskręst mlisłe magąbińtwy dawyków.Młysięga: Rzeczuwki tamił śrąciena zgieł zbronił;Ny mustani… Lejądeź bugy bujst postszez zbegałą.Z zazorzą się jeneśJarało jak do erw\n",
            "epoch 31\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 2.0827\n",
            "epoch 32\n",
            "277/277 [==============================] - 20s 73ms/step - loss: 2.0697\n",
            "epoch 33\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 2.0581\n",
            "epoch 34\n",
            "277/277 [==============================] - 19s 70ms/step - loss: 2.0467\n",
            "epoch 35\n",
            "277/277 [==============================] - 20s 74ms/step - loss: 2.0346\n",
            "epoch 36\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 2.0234\n",
            "epoch 37\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 2.0122\n",
            "epoch 38\n",
            "277/277 [==============================] - 20s 72ms/step - loss: 2.0020\n",
            "epoch 39\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 1.9913\n",
            "epoch 40\n",
            "277/277 [==============================] - 21s 75ms/step - loss: 1.9804\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba chrocił się po się z powiecie,I czasem się w trzecie wielki po się z pokorzy,I wielki w chodzie zabrani po się z powiecie,I czasem się po się wiemknie się nie powiecie,I przy strzymał się w powieci się nie się z mucha,W niem się z przysiąc się wiech, jak w porebnie strzecił,Jak wielki się na nie podkomorzy się wieci,A mo się wiem nie mochał się nie przecież po stronie,I nie przysiąc się przywieci s\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.5\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba chodzić, po i powieczniko,Przecie, nie nim się jak ogrzydę nie po domuczy;A chwał zmowy i mieszczy, wielki przywiecicy,By rozku porwugał wszystki przyschorną wiemku,Z zrobił się przez waraz dostał się nie podkomu.W chosuki się przechaż przysia w niemtych trónki,Ze długi sprzy wiech nie podem nieci pobieczy.Teraz nie wielki potem wielkie się w stomą,Jestem piercich po mórnie mówił prawie się płońwa,\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.0\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czy onwewowe nigłą; prwoczęcta.I roszyć whóżca treszczyc, wpach szloty głowacha,Widzianym młowenie, jadsty przebrąsłychamiemObarać stromi, wsiędze, naz wiatremlych i męczeKashanionymiumony w gokę — ciodzieni;Całaż mięstwa oczym się Mobły popręska.;Po turoby sznikaka, iBazdaść miłami!Oż wożssie: pojerwia: a z KumieniećZ kisienieńcy obłagrarku, obrach skluci kiÓki,A nim nie porewnie, rzekł móź muchie\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba cośnic, chłuż dziepobniycza(Zozianejowny uwłę, nie Sęschorow niegości…Za… amowolutuwzyby: Mucowy karem,Czercznien, nopny się niechoncza, sznacztonićwdzi,Jeść na nie stąc zoszyć z mię oczartu odstata:Wiernodziej ziszkość: jest joż móztał? pokłachaDziesza twarzkozpnyziela odalnymó, luca!Sam, wiego Mocy! —Oli gdzim i ducem rękę kłodnimi*,Wstuwił, nieźwiatymem knie w mąreglepojemi,Co dybek łajczięckie \n",
            "epoch 41\n",
            "277/277 [==============================] - 21s 74ms/step - loss: 1.9709\n",
            "epoch 42\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 1.9616\n",
            "epoch 43\n",
            "277/277 [==============================] - 20s 74ms/step - loss: 1.9522\n",
            "epoch 44\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 1.9432\n",
            "epoch 45\n",
            "277/277 [==============================] - 20s 72ms/step - loss: 1.9334\n",
            "epoch 46\n",
            "277/277 [==============================] - 21s 76ms/step - loss: 1.9251\n",
            "epoch 47\n",
            "277/277 [==============================] - 20s 74ms/step - loss: 1.9166\n",
            "epoch 48\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 1.9085\n",
            "epoch 49\n",
            "277/277 [==============================] - 20s 73ms/step - loss: 1.9006\n",
            "epoch 50\n",
            "277/277 [==============================] - 21s 76ms/step - loss: 1.8915\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czasem, przymała się postał,A do kończył w domu w domu przy szlachcie,Za szlachta w kończerze pod kończył się podzienie,A przech przech pod wielkiem na trzech przed szlachcie,Od wielkie się zamarszał się na tej szlachciał,A przez obrach się z postał się pod szlachta,Tak w domu się podkochał się przech prostach,W komają się skorzył się z postał się przywiał,A na koniec się w postał z przystał się pr\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.5\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czasem, wiech nale w krwy zawał,I przymałt na niebodził się. «Przech od to okrodu,Jak tako dawną pod pomodzić się po rodzie,Przy na przyzała para, strony z gosi zbiera.Asterąz o tak parak w tem na nie był obną:Włoły się to wielki przechał się się przepadać.Słyszcze za głowę zamku od sobie szlachta,Przymiesz, czy w domu był miedźwieszko prosił,Powiedziałem, a podę swym te skorzej słowy.Tu Postał w p\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.0\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czase, gdybusze skłót zbytę.Była star Jeźli papierł weźszarw i drogą, —Pan Zosiał schurzałec zaż gtyśmi nardyną,Ni posiężekił rodać *trod śmieszmu przywami,Iby żnie z Tadeuszsza czerozy i nasy,Rubak en ta obwiego dziewił i ściedzię.Miecho z dobra scugowa zagać w ten postusza,I podszy: półta zmająco pszerze krąsinnymy,Wstowetź o damturę wszystka, rzekł ifsna prytu.Więceć: co potciał zabłemón a jakno\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba co cało. Prabić. Datżemą słołyKo nim be słowem tumia szlachtom rapież,!…Też mierz, dziwła:… »ch sRawem leczył, zaszcząBałetny jającembyś seklewy mielkiTykez zaśmały, zobszął,,»ż żeśnialszpanka, poleśncą wyidział tylące:Patrzę i prabo ; podma —, że że alki obek;Nik oczaciem: Muci, łama, «le, śsoda:Użem, dwun Waresach:» wyichach? «ch tziesz;W obadła! Pomak idąbszki strosepowędem,Tłumaro zna twószu,* \n",
            "epoch 51\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 1.8848\n",
            "epoch 52\n",
            "277/277 [==============================] - 20s 70ms/step - loss: 1.8754\n",
            "epoch 53\n",
            "277/277 [==============================] - 19s 68ms/step - loss: 1.8676\n",
            "epoch 54\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 1.8603\n",
            "epoch 55\n",
            "277/277 [==============================] - 20s 71ms/step - loss: 1.8539\n",
            "epoch 56\n",
            "277/277 [==============================] - 19s 70ms/step - loss: 1.8465\n",
            "epoch 57\n",
            "277/277 [==============================] - 21s 76ms/step - loss: 1.8395\n",
            "epoch 58\n",
            "277/277 [==============================] - 19s 69ms/step - loss: 1.8322\n",
            "epoch 59\n",
            "277/277 [==============================] - 19s 70ms/step - loss: 1.8249\n",
            "epoch 60\n",
            "277/277 [==============================] - 20s 73ms/step - loss: 1.8184\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.2\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba czasem na wielkim się w kranie,On wielkiej czystej powielany w koniecie,I wielki w szerem zamku wielkiej powiera,I ten starem wielkiej powiesza w konienie,I ten się z powiesza w tym zaczerze się w polu,I z wielkiej od starym przerwała się w karanie,Tak wielkie z wielkiej podniesz na wielkiej wiecie.Tak wielki w tym się zaczał w powiegnie się z mienie,Oczas się z polej w niemnie w starem na wielkiej\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 0.5\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba chłopany głową nie miało — to głowy,W głowę tak i westarna pan wielki w owielka,Nie chłopcie na wojnam szej skinien domowy,Zakanie w tyle w zamiasz wielnie zasłunacze,A mieszka znowa w biegną w karło na konawy,Lecz zatrzała się na się z wielkiej okorzy;W politał i też pole! — jak wielkim zamienie,Zwini staren pan wielki, czarną na prosiela,On niejmienie z głowę w nasz nie miejste panie.Panarne wiel\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.0\n",
            "460\n",
            "Wygenerowany text: Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba ciemnym, ni zechrow okiema:Te dzieco Sółnemu stroną, żedłowawszy.Onapnę, wystoła zniewczana ędzielantoPotowana i i pan jeształ zabraniłem.Zwłanią odciąc jakiem to Sędziego zamy:Nawytła ciejąc, prodaśmy, to starzystu uczę;Anby pan Teraz, krzyknął, zamała z obwonaDzianku rezrciwy grani, czyśliwym powiny;Ale wstarawiem! W truch się alko prawę dkoczył?»Bo an, Rzegra w udał: «Debrze uczyść schodaOgół, o\n",
            "--- Generowanie przy użyciu tekstu początkowego: \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
            "------ Wartość parametru temperature: 1.2\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "for epoch in range(1, 100):\n",
        "    print('epoch', epoch)\n",
        "    # Jedna iteracja trenowania modelu na dostępnych danych treningowych.\n",
        "    model.fit(x, y,\n",
        "              batch_size=512,\n",
        "              epochs=1)\n",
        "\n",
        "    if epoch in [10, 20, 30, 40, 50, 60, 70, 80, 90, 99]:\n",
        "        for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "            # Losowanie tekstu początkowego.\n",
        "            start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "            generated_text = text[start_index: start_index + maxlen]\n",
        "            generated_text = \"Litwo! Ojczyzno moja! ty jesteś jak zdrowie:Ile cię trzeba c\"\n",
        "            print('--- Generowanie przy użyciu tekstu początkowego: \"' + generated_text + '\"')\n",
        "            generated_text_all = generated_text\n",
        "            print('------ Wartość parametru temperature:', temperature)\n",
        "\n",
        "          # Generowanie 400 znaków (proces rozpoczyna się od wylosowanego tekstu początkowego).\n",
        "            for i in range(400):\n",
        "                sampled = np.zeros((1, maxlen, len(chars)))\n",
        "                for t, char in enumerate(generated_text):\n",
        "                    sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "                preds = model.predict(sampled, verbose=0)[0]\n",
        "                next_index = sample(preds, temperature)\n",
        "                next_char = chars[next_index]\n",
        "\n",
        "                generated_text += next_char\n",
        "                generated_text_all += next_char\n",
        "                generated_text = generated_text[1:]\n",
        "\n",
        "            print(len(generated_text_all))\n",
        "            print(f\"Wygenerowany text: {generated_text_all}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n6Fa08YViZ7S",
      "metadata": {
        "id": "n6Fa08YViZ7S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e09238",
      "metadata": {
        "id": "99e09238"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d05eb0",
      "metadata": {
        "id": "27d05eb0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}